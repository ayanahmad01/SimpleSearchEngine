#AccioJob Placement Readiness Major Project.
## SIMPLE SEARCH ENGINE with WEB CRAWLER

#A search engine is a tool that allows users to search for information, images, videos, and more on the internet.

#The project is about implementing a simple search engine and understanding how it works behind the scenes.

#Highlights of the project:

  The project allows users to search for top 30 results according to their query and displays their search history.

  The two main functions of the project are to perform a search and to get user search history.

  The web application consists of three major components: front end, back end, and database.

    Front end: Responsible for the client-side of the application, where the user interacts with the application.

    Back end: Handles the server-side of the application, processing requests from the client and generating responses.

    Database: Stores and manages the data used by the web application.

  The client makes requests to the server for data, calculations, or other operations it cannot perform. The server handles the request and generates a response to the client.
  
    Front end is the client-side application, and back end is the server-side application.
  
    The front end sends requests to the back end, and the back end fulfills the requests and generates responses.

  Technologies used-

    HTML is used for the front end, which is responsible for creating the structure of the web page.

    CSS is used for styling the web page, including elements such as background color, font color, and alignment.
  
    JSP (Java Server Pages) is used to connect the front end to the back end by allowing Java code to be written inside HTML files.

    Java Servlets is used for the back end, specifically for creating multiple mini servers to handle different types of calculations or operations.

    MySQL database management system, is used for storing and interacting with data.

  # Web Crawler

    A web crawler is a bot that crawls over the Internet to gather page data.

    The bot uses an algorithm called DFS (Depth-First Search) to navigate through web pages.

  # MySQL Database

    In this project, MySQL is used as our Relational Database Management System (RDBMS) to store our collections of data.









